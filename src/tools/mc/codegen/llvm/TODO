LLVM backend todo list

***** Larger Items *****

    - Heap Limit Checks
        As discussed with John, some LLVM optimizations may break heap limit
        checks since we add them at CFG time (in particular, consider unrolling
        a loop which performs allocation, the constant we compare against
        to check the headroom in the heap would be wrong).
        
        We also intend to perform these types of optimizations in our 
        compiler and not LLVM. Thus, we will only run passes which do not
        violate the heap limit checks (ones which do not change loops),
        and just perform cleanup and simplification.
        
        If we wanted to allow all optimizations in LLVM, we would need to
        implement an intrinsic that delays evaluation of the constant,
        and also add a pass that lowers that intrinsic to a constant value,
        and place that pass at the very end of the pass ordering. Here's an
        example of such an intrinsic:
        
        %minHeapSpace = call i64 @llvm.experimental.maxOffset(i64* %allocPtr)
        
        Then, we need to do a data flow from that point until all branches
        reach a maxOffset call, and then compute the largest address offset
        among all paths. We would probably also need to allow for maxOffset coalescing
        (consider several of them ending up in a big basic block after inlining),
        so we would need to figure out a way to make other optimization passes
        aware of how to treat the intrinsic. We could also try to make use of
        llvm's safepoints, but they're likely not compatible with call/cc.
        
        
    - Linking in the Runtime System
    
        linking in the runtime system and generating the final binary
        one area we should be careful of here is the RTS glue code that 
        needs to be changed if the llvm backend is used. Perhaps even on 
        each side of the glue in the RTS code in that big switch loop of 
        RunManticore, some things might have to be tweaked.
        
        should just need to make sure we respect the ABI, with the added 
        complexity of using the naked attribute. we might want to setup the 
        stack pointer upon entering manticore function land to be 8 bytes 
        shy of a 16 byte alignment so callq aligns the stack for us. this 
        is of course not considering other things like what if the reg alloc
        decided to use push for spills, and we make a c call in the middle 
        of a basic block. I believe we need to browse the LLVM source code 
        to find out how the naked attribute is treated, because that 
        preliminary testing earlier yielded some hoops that needed to be 
        jumped through (mostly, I remember needing to call a special stack 
        realigner function before making the actual c call to match the 16 
        byte ABI spec. we could always introduce a pass that inserts that r
        ealignment in a target non-specific way into LLVM's code generator, 
        because I think this is an oversight.... we're probably the only 
        people seriously making use of that attribute)
        
        alignstack(<n>)
        This attribute indicates that, when emitting the prologue and 
        epilogue, the backend should forcibly align the stack pointer. 
        Specify the desired alignment, which must be a power of two, in 
        parentheses.
        
        ALSO: what the heck is this "thunk" attribute. also it seems 
        musttail is "optimization hostile" http://reviews.llvm.org/D11476
        and I was able to confirm that slightly more optimizations 
        occurred (inlines, loop transforms, folds etc) after changing
        "musttail" to "tail". so there must be a few types of 
        constructs we generate that are not as friendly, but we're 
        mostly fine.
        
    
    

***** Medium Items *****

    - Floating point literals: John is taking care of this.      

    - Allocation Fixes
          determine the header tag bits for allocations.



***** Small Items *****

    - BUG: the data layout string says i8's are 64 byte aligned, thus LLVM
           decides to make the following transformation because it's now legal:
           
           %r_13056 = bitcast i64** %r_13055 to i8*
           %r_13057 = getelementptr inbounds i8, i8* %r_13056, i64 1024
           TO
           %r_130571 = getelementptr inbounds i64*, i64** %r_13055, i64 1024
           
           the bug is that vproc offset calculations currently use that type of
           bitcast followed by a GEP. You need to make it so that only SELECT,
           UPDATE, and allocations use GEP with this type of datalayout string.
           Vproc pointers should use standard pointer arithmetic.
    
    - The remaining unimplemented primops, which is the AllocVectorX and and memory fence/pause instructions.
    
    - Add some aliasing information for the allocation pointer.
    
        We can use the 'noalias' attribute on the parameter of every function which is the allocation pointer.
        This will require changing the jwaCC type list (so the first one is an LT.allocPtrTy instead of an i64)
        and also adding a block of function prototype declarations, because only in the prototypes can you write
        noalias. This attribute corresponds to the 'restrict' keyword in C99. https://en.wikipedia.org/wiki/Restrict
        
        
    - Pick passes that do not modify the CFG and perform quick cleanup/optimization of the code we generate before handing it off to LLC.
      Here's an example pass ordering:
      
        -verify -tailcallelim -simplifycfg -domtree -constprop -early-cse -basicaa -gvn -globalopt -reassociate -early-cse -domtree -basicaa -memdep -instcombine -adce -globaldce -instcombine -barrier -domtree -branch-prob -constmerge -verify -stats -time-passes
        
        It's important to note that I'm not personally convinced opt can do anything useful for us with the restrictions about modifying the CFG after looking at what llc generates with -O3. maybe all we need is constprop, reassociate, early-cse, instcombine, adce, instcombine. llc will handle the rest. we also might need to be careful about llc messing up alloc checks. that really is what's next up.
        
    
    - Maybe a bug? (or just change it so we dont annoy the linter): 
      because we are not binding constants at the same point
      in LLVM as we do in CFG, we're kind of doing our own constant propagation
      during translation (because LLVM does not allow %lhs = i64 1, you need
      to use a dummy bitcast trick), and this is what I believe is causing the
      LLVM linter to warn about casting the constant 1 to a pointer. here's
      an example in wakeupSleepingThreads, which deals with lists (thus 1 is nil
      and a 2 aligned pointer is a cons cell)

else_cfg1072E_18B31:
    %con_nil_cfg1072C_18B58 = phi i64 [ 1, %wakeupSleepingThreadsCheck_cfg12BE1_18B33 ]
	%r_18BDB = icmp ne i64 %con_nil_cfg1072C_18BD9, 1
	br i1 %r_18BDB, label %then_cfg10779_18B2E, label %else_cfg10786_18B2D

then_cfg10779_18B2E:
    %con_nil_cfg10777_18B3F = phi i64 [ %con_nil_cfg1072C_18B58, %else_cfg1072E_18B31 ]
    %con_nil_cfg10777_18B6E = inttoptr i64 %con_nil_cfg10777_18B3F to %_tupTy.1*
	%r_18B6F = getelementptr inbounds %_tupTy.1, %_tupTy.1* %con_nil_cfg10777_18B6E, i32 0, i32 0
	%r_18B70 = load i64*, i64** %r_18B6F
